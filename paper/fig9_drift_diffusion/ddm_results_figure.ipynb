{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ddm_utils import (\n",
    "    encode_zero_choice_as_negative_rts,\n",
    "    parallel_simulator,\n",
    "    simulate_ddm_collapsing,\n",
    ")\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.inference import MNLE\n",
    "from sbi.inference.posteriors import MCMCPosteriorParameters\n",
    "from scipy.stats import binom\n",
    "\n",
    "from paper.colors import colors\n",
    "\n",
    "colors_red = mpl.cm.Reds(np.linspace(0.3, 1, 5))\n",
    "tue = (165 / 255, 30 / 255, 55 / 255)\n",
    "gold = (180 / 255, 160 / 255, 105 / 255)\n",
    "dark = (50 / 255, 65 / 255, 75 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading results\n",
    "with open(\"data/sbi_ddm_collapsing_prior_theta_x.pkl\", \"rb\") as f:\n",
    "    prior, theta, x = pickle.load(f)\n",
    "\n",
    "density_estimator = torch.load(\"data/ddm_collapsing_estimator.pt\", weights_only=False)\n",
    "# build posterior with pre-trained density estimator\n",
    "inferer = MNLE()\n",
    "\n",
    "mcmc_parameters = MCMCPosteriorParameters(\n",
    "    num_chains=100,\n",
    "    thin=2,\n",
    "    warmup_steps=500,\n",
    "    init_strategy=\"sir\",\n",
    ")\n",
    "\n",
    "posterior = inferer.build_posterior(\n",
    "    prior=prior,\n",
    "    density_estimator=density_estimator,\n",
    "    posterior_parameters=mcmc_parameters,\n",
    ")\n",
    "\n",
    "with open(\"data/ddm_collapsing_diagnostics.pt\", \"rb\") as f:\n",
    "    ranks, daps = pickle.load(f).values()\n",
    "    num_sbc_samples = len(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating observed data\n",
    "seed = 42\n",
    "simulator = parallel_simulator(num_workers=10, show_progress=True, seed=seed)(\n",
    "    simulate_ddm_collapsing\n",
    ")\n",
    "\n",
    "num_trials = 100\n",
    "theta_o1 = torch.tensor([[-0.125, 0.35, -0.2, 0.5, -0.7]])\n",
    "theta_o2 = torch.tensor([[0.125, 0.55, 0.2, 0.3, -0.5]])\n",
    "x_o1 = simulator(theta_o1.repeat(num_trials, 1))\n",
    "x_o2 = simulator(theta_o2.repeat(2 * num_trials, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re-)Run inference\n",
    "rerun = False\n",
    "num_posterior_samples = 1000\n",
    "\n",
    "if rerun:\n",
    "    posterior_samples1 = posterior.sample((num_posterior_samples,), x=x_o1)\n",
    "    posterior_samples2 = posterior.sample((num_posterior_samples,), x=x_o2)\n",
    "\n",
    "    with open(\"data/ddm_collapsing_posterior_samples.pkl\", \"wb\") as f:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"posterior_samples1\": posterior_samples1,\n",
    "                \"posterior_samples2\": posterior_samples2,\n",
    "            },\n",
    "            f,\n",
    "        )\n",
    "else:\n",
    "    with open(\"data/ddm_collapsing_posterior_samples.pkl\", \"rb\") as f:\n",
    "        posterior_samples = torch.load(f, weights_only=False)\n",
    "        posterior_samples1 = posterior_samples[\"posterior_samples1\"]\n",
    "        posterior_samples2 = posterior_samples[\"posterior_samples2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictive samples\n",
    "num_predictive_samples = 1000\n",
    "x_o_dist1 = simulator(theta_o1.repeat(num_predictive_samples, 1))\n",
    "x_o_dist1 = encode_zero_choice_as_negative_rts(x_o_dist1)\n",
    "x_o_dist2 = simulator(theta_o2.repeat(num_predictive_samples, 1))\n",
    "x_o_dist2 = encode_zero_choice_as_negative_rts(x_o_dist2)\n",
    "\n",
    "posterior_pred1 = encode_zero_choice_as_negative_rts(simulator(posterior_samples1))\n",
    "posterior_pred2 = encode_zero_choice_as_negative_rts(simulator(posterior_samples2))\n",
    "\n",
    "prior_pred = encode_zero_choice_as_negative_rts(x[:num_predictive_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ddm_collapsing_calibration_samples.pt\", \"rb\") as fh:\n",
    "    thetas, xs, sbc_posterior_samples = pickle.load(fh).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARP and SBC\n",
    "\n",
    "from sbi.diagnostics.sbc import _run_sbc\n",
    "from sbi.diagnostics.tarp import _run_tarp, get_tarp_references\n",
    "\n",
    "_ = torch.manual_seed(0)\n",
    "marginal_ranks = _run_sbc(\n",
    "    thetas,\n",
    "    xs,\n",
    "    posterior_samples=sbc_posterior_samples,\n",
    "    reduce_fns=\"marginals\",\n",
    ")\n",
    "ep_ranks = _run_sbc(\n",
    "    thetas,\n",
    "    xs,\n",
    "    posterior_samples=sbc_posterior_samples,\n",
    "    reduce_fns=posterior.potential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarp_references = get_tarp_references(thetas)\n",
    "ecp, alpa = _run_tarp(\n",
    "    posterior_samples=sbc_posterior_samples,\n",
    "    thetas=thetas,\n",
    "    references=tarp_references,\n",
    "    num_bins=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "histtype = \"step\"\n",
    "repeats = 50\n",
    "# how to use latex typesetting\n",
    "# mpl.rcParams[\"text.usetex\"] = True\n",
    "# mpl.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsmath}\"\n",
    "labels = [r\"$v$\", r\"$a$\", r\"$w$\", r\"$\\tau$\", r\"$\\gamma$\"]\n",
    "num_params = len(labels)\n",
    "limits = [\n",
    "    [prior.base_dist.low[i].item(), prior.base_dist.high[i].item()]\n",
    "    for i in range(prior.base_dist.low.shape[0])\n",
    "]\n",
    "\n",
    "# panel c\n",
    "with mpl.rc_context(fname=\"../../.matplotlibrc\"):\n",
    "    fig, ax = plt.subplots(num_params, num_params, figsize=(3.2, 3.2))\n",
    "    fig, ax = pairplot(\n",
    "        [posterior_samples1, posterior_samples2],\n",
    "        points=[theta_o1, theta_o2],\n",
    "        limits=limits,\n",
    "        ticks=limits,\n",
    "        samples_colors=[colors[\"theta_shades\"][1], colors[\"theta_shades\"][4]],\n",
    "        diag=\"hist\",\n",
    "        upper=\"scatter\",\n",
    "        kde_offdiag=dict(bw_method=\"scott\", bins=50),\n",
    "        contour_offdiag=dict(levels=[0.95], percentile=True),\n",
    "        scatter_offdiag=dict(s=2),\n",
    "        hist_diag=dict(bins=20, histtype=histtype),\n",
    "        points_offdiag=dict(marker=\"+\", markersize=4, mew=0.5),\n",
    "        points_diag=dict(linewidth=0.5),\n",
    "        points_colors=[\"k\", \"k\"],\n",
    "        fig=fig,\n",
    "        axes=ax,\n",
    "        labels=labels,\n",
    "    )\n",
    "    for i in reversed(list(range(5))):\n",
    "        ax[i, i].set_xlabel(labels[i], labelpad=-5)\n",
    "        for label in ax[i, i].get_xticklabels():\n",
    "            label.set_clip_on(False)\n",
    "            label.set_zorder(10_000)\n",
    "        ax[i, i].set_zorder(1000 - i)\n",
    "    # mpl.rcParams[\"text.usetex\"] = False\n",
    "    plt.sca(ax[0, 0])\n",
    "    legend = plt.legend(\n",
    "        [\n",
    "            \"Subject 1 (100 trials)\",\n",
    "            \"Subject 2 (200 trials)\",\n",
    "            r\"$\\theta_o$\",\n",
    "        ],\n",
    "        bbox_to_anchor=(0.2, -4.35),\n",
    "        # handlelength=0.6,\n",
    "        loc=2,\n",
    "    )\n",
    "    for handle in legend.get_patches():\n",
    "        handle.set_height(0.1)\n",
    "        handle.set_y(handle.get_y() + 2.0)\n",
    "    plt.savefig(\"svg/posterior_pairplot.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel: Predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(fname=\"../../.matplotlibrc\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(3, 1.0), sharex=True, sharey=True)\n",
    "\n",
    "    # plot for each subject\n",
    "    plt.sca(ax[0])\n",
    "    _, bins = np.histogram(prior_pred.numpy(), bins=50)\n",
    "    for sample, color in zip(\n",
    "        [prior_pred, x_o_dist1, posterior_pred1],\n",
    "        [colors[\"x_shades\"][0], colors[\"x_o\"], colors[\"x\"]],\n",
    "    ):\n",
    "        plt.hist(\n",
    "            sample.numpy(),\n",
    "            bins=bins,\n",
    "            density=True,\n",
    "            histtype=histtype,\n",
    "            color=color,\n",
    "            # linewidth=linewidth,\n",
    "        )\n",
    "\n",
    "    ax[0].spines[\"left\"].set_visible(False)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"$x$: reaction time (sec)\")\n",
    "    ticks = np.array([-2, -1, 0, 1, 2])\n",
    "    plt.xticks(ticks, abs(ticks))\n",
    "    plt.xlim([ticks.min(), ticks.max()])\n",
    "\n",
    "    # Arrows\n",
    "    #     plt.axvline(0, color=\"k\")\n",
    "    axis_setoff = -0.02\n",
    "\n",
    "    plt.sca(ax[1])\n",
    "    for sample, color in zip(\n",
    "        [prior_pred, x_o_dist2, posterior_pred2],\n",
    "        [colors[\"x_shades\"][0], colors[\"x_o\"], colors[\"x\"]],\n",
    "    ):\n",
    "        plt.hist(\n",
    "            sample.numpy(),\n",
    "            bins=bins,\n",
    "            density=True,\n",
    "            histtype=histtype,\n",
    "            color=color,\n",
    "            # linewidth=linewidth,\n",
    "        )\n",
    "\n",
    "    ax[1].spines[\"left\"].set_visible(False)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"$x$: reaction time (sec)\")\n",
    "    ticks = np.array([-2, -1, 0, 1, 2])\n",
    "    plt.xticks(ticks, abs(ticks))\n",
    "    plt.xlim([ticks.min(), ticks.max()])\n",
    "\n",
    "    # Create handles for the legend\n",
    "    prior_handle = plt.Line2D([0], [0], color=colors[\"x_shades\"][0], lw=2)\n",
    "    x_o_handle = plt.Line2D([0], [0], color=colors[\"x_o\"], lw=2)\n",
    "    post_handle1 = plt.Line2D([0], [0], color=colors[\"x\"], lw=2)\n",
    "    post_handle2 = plt.Line2D([0], [0], color=colors[\"x\"], lw=2)\n",
    "\n",
    "    # Group the two posterior handles\n",
    "    post_handles = (post_handle1, post_handle2)\n",
    "\n",
    "    # Create the legend with proper grouping\n",
    "    handles = [prior_handle, x_o_handle, post_handles]\n",
    "    labels = [\"prior \\npredictive\", \"$x_o$\", \"posterior \\npredictive\"]\n",
    "\n",
    "    # Add legend with custom handler\n",
    "    fig.legend(\n",
    "        handles=handles,\n",
    "        labels=labels,\n",
    "        bbox_to_anchor=(0.67, 0.95),\n",
    "        handlelength=0.6,\n",
    "        frameon=False,\n",
    "        #         handler_map={tuple: plt.matplotlib.legend_handler.HandlerTuple(ndivide=None)},\n",
    "    )\n",
    "    ax[0].set_title(\"Subject 1\")\n",
    "    ax[1].set_title(\"Subject 2\")\n",
    "\n",
    "    # Arrows\n",
    "    #     plt.axvline(0, color=\"k\")\n",
    "    axis_setoff = -0.02\n",
    "\n",
    "    plt.savefig(\"svg/posterior_predictives.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel coverage checks combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(fname=\"../../.matplotlibrc\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(1.1, 1.1))\n",
    "\n",
    "    # Plot for marginal ranks\n",
    "    alphas = np.linspace(0.1, 0.7, num_params)\n",
    "    lines = []\n",
    "    for jj in range(num_params):\n",
    "        hist, *_ = np.histogram(marginal_ranks[:, jj], bins=nbins, density=False)\n",
    "        histcs = hist.cumsum()\n",
    "        line = ax.plot(\n",
    "            np.linspace(0, nbins, repeats * nbins),\n",
    "            np.repeat(histcs / histcs.max(), repeats),\n",
    "            label=\"SBC\",\n",
    "            color=colors[\"theta_shades\"][0],\n",
    "            alpha=alphas[jj],\n",
    "        )\n",
    "        lines.append(line[0])\n",
    "\n",
    "    hb = binom(num_sbc_samples, p=1 / nbins).ppf(0.5) * np.ones(nbins)\n",
    "    hbb = hb.cumsum() / hb.sum()\n",
    "    hbb[-1] -= 1e-9\n",
    "    lower = [binom(num_sbc_samples, p=p).ppf(0.005) for p in hbb]\n",
    "    upper = [binom(num_sbc_samples, p=p).ppf(0.995) for p in hbb]\n",
    "\n",
    "    ax.fill_between(\n",
    "        x=np.linspace(0, nbins, repeats * nbins),\n",
    "        y1=np.repeat(lower / np.max(lower), repeats),\n",
    "        y2=np.repeat(upper / np.max(lower), repeats),\n",
    "        color=\"grey\",\n",
    "        linewidth=0,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    # Plot for EP and TARP\n",
    "    hist, *_ = np.histogram(ep_ranks, bins=nbins, density=False)\n",
    "    histcs = hist.cumsum()\n",
    "    ep_line = ax.plot(\n",
    "        np.linspace(0, nbins, repeats * nbins),\n",
    "        np.repeat(histcs / histcs.max(), repeats),\n",
    "        color=colors[\"theta_shades\"][4],\n",
    "        alpha=0.7,\n",
    "        label=\"Exp. Cov.\",\n",
    "    )\n",
    "    tarp_line = ax.plot(\n",
    "        np.linspace(0, len(ecp), repeats * len(ecp)),\n",
    "        np.repeat(ecp / ecp.max(), repeats),\n",
    "        color=colors[\"theta_shades\"][2],\n",
    "        alpha=0.7,\n",
    "        label=\"TARP\",\n",
    "    )\n",
    "\n",
    "    hb = binom(num_sbc_samples, p=1 / nbins).ppf(0.5) * np.ones(nbins)\n",
    "    hbb = hb.cumsum() / hb.sum()\n",
    "    hbb[-1] -= 1e-9\n",
    "    lower = [binom(num_sbc_samples, p=p).ppf(0.005) for p in hbb]\n",
    "    upper = [binom(num_sbc_samples, p=p).ppf(0.995) for p in hbb]\n",
    "\n",
    "    ax.fill_between(\n",
    "        x=np.linspace(0, nbins, repeats * nbins),\n",
    "        y1=np.repeat(lower / np.max(lower), repeats),\n",
    "        y2=np.repeat(upper / np.max(lower), repeats),\n",
    "        color=\"grey\",\n",
    "        linewidth=0.0,\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    # Set labels, ticks, and limits\n",
    "    ax.set_yticks(np.linspace(0, 1, 3))\n",
    "    ax.set_ylabel(\"empirical CDF\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(0, nbins)\n",
    "    ax.set_xticks(np.linspace(0, nbins, 3))\n",
    "    ax.spines[\"left\"].set_position((\"axes\", axis_setoff))\n",
    "    ax.spines[\"bottom\"].set_position((\"axes\", axis_setoff))\n",
    "    ax.set_xlabel(\"rank / coverage level\")\n",
    "\n",
    "    legend2 = ax.legend(\n",
    "        handles=[ep_line[0], tarp_line[0], lines[4]],\n",
    "        loc=\"lower right\",\n",
    "        bbox_to_anchor=(0.78, 0.52),\n",
    "        handlelength=0.4,\n",
    "        handletextpad=0.4,\n",
    "        labelspacing=0.2,\n",
    "        # title=\"EP and TARP\",\n",
    "    )\n",
    "\n",
    "    plt.savefig(\"svg/combined_coverage_checks.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as IPd\n",
    "from svgutils.compose import SVG, Figure, Panel, Text\n",
    "\n",
    "\n",
    "def svg(img):\n",
    "    IPd.display(\n",
    "        IPd.HTML(\n",
    "            '<img src=\"{}\" / >'.format(\n",
    "                img,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# > Inkscape pixel is 1/90 of an inch, other software usually uses 1/72.\n",
    "# > http://www.inkscapeforum.com/viewtopic.php?f=6&t=5964\n",
    "svg_scale = 1.25  # set this to 1.25 for Inkscape, 1.0 otherwise\n",
    "\n",
    "# Panel letters in Helvetica Neue, 12pt, Medium\n",
    "kwargs_text = {\"size\": \"10pt\", \"font\": \"Arial\", \"weight\": \"800\"}\n",
    "kwargs_text_normal = {\"size\": \"7pt\", \"font\": \"Arial\"}\n",
    "\n",
    "dy = 154\n",
    "\n",
    "f = Figure(\n",
    "    \"18.0cm\",\n",
    "    \"7.3cm\",\n",
    "    Panel(\n",
    "        SVG(\"svg/panel_a.svg\").scale(1.0),\n",
    "    ).move(0, 0),\n",
    "    Panel(\n",
    "        SVG(\"svg/posterior_pairplot.svg\").scale(svg_scale),\n",
    "        Text(\"c\", -5, 0.0, **kwargs_text),\n",
    "        Text(\"Posterior 1D and 2D marginals\", 60, 0, **kwargs_text_normal),\n",
    "    ).move(420, 12),\n",
    "    Panel(\n",
    "        SVG(\"svg/posterior_predictives.svg\").scale(svg_scale),\n",
    "        Text(\"d\", -5, 0, **kwargs_text),\n",
    "        Text(\"Posterior predictive checks\", 50, 0, **kwargs_text_normal),\n",
    "    ).move(5, dy),\n",
    "    Panel(\n",
    "        SVG(\"svg/combined_coverage_checks.svg\").scale(svg_scale),\n",
    "        Text(\"e\", 5, 0, **kwargs_text),\n",
    "        Text(\"Calibration diagnostics\", 25, 0, **kwargs_text_normal),\n",
    "    ).move(250, dy - 2.5),\n",
    ")\n",
    "\n",
    "!mkdir -p fig\n",
    "f.save(\"fig/fig7.svg\")\n",
    "svg(\"fig/fig7.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi-practical-guide (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
